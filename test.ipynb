{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1132200,
     "status": "ok",
     "timestamp": 1556853692233,
     "user": {
      "displayName": "Hiệp Hoàng",
      "photoUrl": "",
      "userId": "17294394885253397311"
     },
     "user_tz": -420
    },
    "id": "kmrPp-bi4zXH",
    "outputId": "f4d9624c-5703-47b3-d033-99b097750e87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 14s 1us/step\n",
      "(50000, 28, 28)\n",
      "Dữ liệu y ban đầu  5\n",
      "Dữ liệu y sau one-hot encoding  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "39616/50000 [======================>.......] - ETA: 18s - loss: 0.3667 - acc: 0.9001"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bf16a89f6619>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m                     metrics=['accuracy'])\n\u001b[0;32m     31\u001b[0m H = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n\u001b[1;32m---> 32\u001b[1;33m                  batch_size=32, epochs=10, verbose=1)\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_val, y_val = X_train[50000:60000,:], y_train[50000:60000]\n",
    "X_train, y_train = X_train[:50000,:], y_train[:50000]\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_val = np_utils.to_categorical(y_val, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "print('Dữ liệu y ban đầu ', y_train[0])\n",
    "print('Dữ liệu y sau one-hot encoding ',Y_train[0])\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "H = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n",
    "                 batch_size=32, epochs=10, verbose=1)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap='gray')\n",
    "y_predict = model.predict(X_test[0].reshape(1,28,28,1))\n",
    "print('Giá trị dự đoán: ', np.argmax(y_predict))\n",
    "model.save_weights(\"C:/Users/admin/Downloads/Project II/model_weights.h5\")\n",
    "print(\"Saved model to drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1557991586457,
     "user": {
      "displayName": "Hiệp Hoàng",
      "photoUrl": "",
      "userId": "17294394885253397311"
     },
     "user_tz": -420
    },
    "id": "fFZNcqbJkuAD",
    "outputId": "8628add6-2d9a-48e0-a972-6fd82ee85088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị dự đoán:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f54b62d64a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADxZJREFUeJzt3X+IXeWdx/HP18kkoA0SLYYhiaYb\ngmAEk2XQDSub6m6CkUIs/qD+sWRd2akQ0cL+YcgiKy4LYtrqIkshtSHJ0rUVTTGEskkNsq4gxfhj\n/VHtxg2pTUwmGQ3EHzGdmXz3jzlZpjr3eW7uOeeeO/N9v2CYe8/3nnOfe+585px7n3POY+4uAPFc\n0HQDADSD8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCGpWN5/MzDicEKiZu1s7jyu15Tezm8zs\nt2b2vpltLLOsyMws+XPBBRckf8qoc9nobR2/u2bWJ+lfJa2VdJWkO83sqqoaBqBeZf61XyvpfXc/\n6O5/kPQzSeuqaRaAupUJ/wJJv590/3Ax7Y+Y2ZCZ7Tez/SWeC0DFav/Cz923SNoi8YUf0EvKbPmP\nSFo06f7CYhqAaaBM+F+RtNTMvmFmsyV9R9KuapoFoG4d7/a7+5iZ3Stpj6Q+SVvd/Z3KWjaD5LrM\ncldTOnv2bG3PXWbZ0kQ3ZQpXiupd1s03J+pn/rLhL/MeEf54unKQD4Dpi/ADQRF+ICjCDwRF+IGg\nCD8QVFfP548q1502a1b6bRgbG0vW+/v7W9ZGR0eT8+aU7aZE72LLDwRF+IGgCD8QFOEHgiL8QFCE\nHwiKrr4umDNnTrJ+5syZUssv251XBl190xdbfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iiqv3TgN9\nfX3J+vj4eMta3VcOrvvqwDh/XL0XQBLhB4Ii/EBQhB8IivADQRF+ICjCDwRV6nx+Mzsk6RNJ45LG\n3H2wikZFkxvpNtWP3878KZyPH1cVF/O4wd1HKlgOgC5itx8Iqmz4XdJeM3vVzIaqaBCA7ii723+9\nux8xs8sk/crM3nP3Fyc/oPinwD8GoMdUdmKPmT0k6VN3/37iMXy7NIXcF3a59yg1f27ZZU+84cSe\n3lP7iT1mdpGZzT13W9IaSW93ujwA3VVmt3++pF8UW5ZZkv7d3f+jklYBqB3n8/eA3K75vHnzkvWd\nO3e2rK1cuTI575NPPpmsb9iwIVkv+5EF1eN8fgBJhB8IivADQRF+ICjCDwRF+IGgGKK7ByxbtixZ\n3717d7J++eWXt6zluuIGBgaSdY7gm7nY8gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUD3Vz99kn3Kd\nz33ZZZcl69u2bUvWc331qXrTQ2yXadsNN9yQrL/wwgvJeuq11fm6pOlxKjNbfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8Iqqf6+XN9r2X6jGfNSr/UsbGxZD3VZ3zppZcm5927d2+yvnTp0mT94MGDyfqK\nFSta1u66667kvO+9916ynlNmePAnnngiWc9dNnzjxo3J+qOPPtqyNmfOnOS8Z86cSdanQz9+Dlt+\nICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgq289vZlslfUvScXe/uph2iaSfS1os6ZCkO9z9ZDtPWKZf\nuEzfaq4fP6e/v79lbfPmzcl5r7nmmmT99OnTyfqaNWuS9eHh4Za1+++/Pzlv3VL96bfeemty3jLX\nMcjJ9ePnzITxDNrZ8m+TdNOXpm2UtM/dl0raV9wHMI1kw+/uL0r6+EuT10naXtzeLumWitsFoGad\nfuaf7+5Hi9vHJM2vqD0AuqT0sf3u7mbW8sO4mQ1JGir7PACq1emWf9jMBiSp+H281QPdfYu7D7r7\nYIfPBaAGnYZ/l6T1xe31kp6rpjkAuiUbfjN7StLLkq40s8NmdrekRyStNrMDkv6quA9gGrFunpec\n+m6gqOfmb1kr26/a19eXrKfOLX/88ceT8+Ze16pVq5L1l156KVkv89pzr3t8fLzjZUvS8uXLW9Ze\nf/315LwjIyPJeu46CKdOnWpZy62zutdLndy9rQMgOMIPCIrwA0ERfiAowg8ERfiBoAg/EFTXL91d\n17DJua6Z3LJzXTe33377ebfpnIcffjhZX7BgQbK+adOmZP2jjz5qWTt5Mn2mde65jx07lqzn1us9\n99yTrKc888wzyfratWuT9dTfxIkTJ5Lz7tmzJ1mfCdjyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ\nXe/nT/ULl7kccq6fPrfs3HECqVOfc6fsPvjgg8l6zpEjR5L1zz77rGUtd8r2xRdf3PGypfxrX7Jk\nSbKecuWVVybrN954Y7Ke+pt4/vnnk/PmhlXPve6ZculuADMQ4QeCIvxAUIQfCIrwA0ERfiAowg8E\n1fV+/lT/aJnLiJcdMjlXT11m+rrrrkvOO3v27GQ9J/faUlJDZEvS6Ohosp4b2vzCCy9M1lPv6Rdf\nfJGcNzUsem7ZkjRrVus/79y8ZevTAVt+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgqO0S3mW2V9C1J\nx9396mLaQ5L+TtK5i59vcvdfZp8sM0R3G/N3PG/ZftlUX/vChQuT8+b6+XPXEvjggw+S9dOnTyfr\nKXPnzk3Wc+fz33fffcn6Y4891rL2wAMPJOfdvHlzst7G327H8+bk/habPA6gyiG6t0m6aYrpj7n7\n8uInG3wAvSUbfnd/UdLHXWgLgC4q85n/XjN708y2mtm8yloEoCs6Df+PJC2RtFzSUUk/aPVAMxsy\ns/1mtr/D5wJQg47C7+7D7j7u7mcl/VjStYnHbnH3QXcf7LSRAKrXUfjNbGDS3W9Lerua5gDoluwp\nvWb2lKRvSvq6mR2W9I+SvmlmyyW5pEOSvltjGwHUINvPX+mTleznj6rOPuUyx05I0tNPP52s33bb\nbS1rV1xxRXLeDz/8MFnPjdUwE86570SV/fwAZiDCDwRF+IGgCD8QFOEHgiL8QFBdv3R3RGW703Jd\nVqnTjcsOFZ279HfusuXDw8Mta59//nly3txlw8vo5VNyu4UtPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8ERT9/F5TtM85d2jt1amvZ/uyVK1cm64sWLUrWd+zY0bI2MjKSnDcnN3R56rVF6MfPYcsPBEX4\ngaAIPxAU4QeCIvxAUIQfCIrwA0HRz98FZfrp26nXeT7/smXLkvXc8g8cONCy1t/fn5w397rLvraU\nMscQtFPvBWz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCobD+/mS2StEPSfEkuaYu7/4uZXSLp55IW\nSzok6Q53P1lfU6evXH91WXUO0b169epkPdcf/vLLL7esjY6OJufNKXOtgrLHXswE7Wz5xyT9vbtf\nJenPJG0ws6skbZS0z92XStpX3AcwTWTD7+5H3f214vYnkt6VtEDSOknbi4dtl3RLXY0EUL3z+sxv\nZoslrZD0a0nz3f1oUTqmiY8FAKaJto/tN7OvSXpW0vfc/dTkz1vu7mY25QcsMxuSNFS2oQCq1daW\n38z6NRH8n7r7zmLysJkNFPUBScenmtfdt7j7oLsPVtFgANXIht8mNvE/kfSuu/9wUmmXpPXF7fWS\nnqu+eQDq0s5u/59L+mtJb5nZG8W0TZIekfS0md0t6XeS7qinicips0ur7KmpJ06caFkrO3R5GWW7\n8nJdnHWeblyVbPjd/SVJrd6lv6y2OQC6hSP8gKAIPxAU4QeCIvxAUIQfCIrwA0Fx6e5pIHeJ67Gx\nsZa1XH9zrr969+7dyfqqVauS9ZMnW5/lnXvusn3xqeMIcscY5NbbdLg0dw5bfiAowg8ERfiBoAg/\nEBThB4Ii/EBQhB8IyrrZX9nqUl8zXZlLTJdd/kzoj+5UmesF5NZb3e9pGe7e1gtnyw8ERfiBoAg/\nEBThB4Ii/EBQhB8IivADQdHPD8ww9PMDSCL8QFCEHwiK8ANBEX4gKMIPBEX4gaCy4TezRWb2gpn9\nxszeMbP7i+kPmdkRM3uj+Lm5/uYCqEr2IB8zG5A04O6vmdlcSa9KukXSHZI+dffvt/1kHOQD1K7d\ng3yyI/a4+1FJR4vbn5jZu5IWlGsegKad12d+M1ssaYWkXxeT7jWzN81sq5nNazHPkJntN7P9pVoK\noFJtH9tvZl+T9J+S/tndd5rZfEkjklzSP2nio8HfZpbBbj9Qs3Z3+9sKv5n1S9otaY+7/3CK+mJJ\nu9396sxyCD9Qs8pO7LGJy5T+RNK7k4NffBF4zrclvX2+jQTQnHa+7b9e0n9JekvSuXGLN0m6U9Jy\nTez2H5L03eLLwdSy2PIDNat0t78qhB+oH+fzA0gi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEH\ngiL8QFCEHwiK8ANBEX4gKMIPBJW9gGfFRiT9btL9rxfTelGvtq1X2yXRtk5V2bYr2n1gV8/n/8qT\nm+1398HGGpDQq23r1XZJtK1TTbWN3X4gKMIPBNV0+Lc0/Pwpvdq2Xm2XRNs61UjbGv3MD6A5TW/5\nATSkkfCb2U1m9lsze9/MNjbRhlbM7JCZvVWMPNzoEGPFMGjHzeztSdMuMbNfmdmB4veUw6Q11Lae\nGLk5MbJ0o+uu10a87vpuv5n1SfofSaslHZb0iqQ73f03XW1IC2Z2SNKguzfeJ2xmfyHpU0k7zo2G\nZGaPSvrY3R8p/nHOc/cHeqRtD+k8R26uqW2tRpb+GzW47qoc8boKTWz5r5X0vrsfdPc/SPqZpHUN\ntKPnufuLkj7+0uR1krYXt7dr4o+n61q0rSe4+1F3f624/YmkcyNLN7ruEu1qRBPhXyDp95PuH1Zv\nDfntkvaa2atmNtR0Y6Ywf9LISMckzW+yMVPIjtzcTV8aWbpn1l0nI15XjS/8vup6d/9TSWslbSh2\nb3uST3xm66Xumh9JWqKJYdyOSvpBk40pRpZ+VtL33P3U5FqT626KdjWy3poI/xFJiybdX1hM6wnu\nfqT4fVzSLzTxMaWXDJ8bJLX4fbzh9vw/dx9293F3Pyvpx2pw3RUjSz8r6afuvrOY3Pi6m6pdTa23\nJsL/iqSlZvYNM5st6TuSdjXQjq8ws4uKL2JkZhdJWqPeG314l6T1xe31kp5rsC1/pFdGbm41srQa\nXnc9N+K1u3f9R9LNmvjG/38l/UMTbWjRrj+R9N/FzztNt03SU5rYDRzVxHcjd0u6VNI+SQckPS/p\nkh5q279pYjTnNzURtIGG2na9Jnbp35T0RvFzc9PrLtGuRtYbR/gBQfGFHxAU4QeCIvxAUIQfCIrw\nA0ERfiAowg8ERfiBoP4P27hX8wLS8PkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "model.load_weights(\"drive/My Drive/Colab Notebooks/model.h5\")\n",
    "img = Image.open(\"drive/My Drive/Colab Notebooks/data/4/four100.jpg\")\n",
    "img = img.resize((28,28))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(im2arr)\n",
    "print('Giá trị dự đoán: ', np.argmax(y_pred))\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 674106,
     "status": "ok",
     "timestamp": 1557991459867,
     "user": {
      "displayName": "Hiệp Hoàng",
      "photoUrl": "",
      "userId": "17294394885253397311"
     },
     "user_tz": -420
    },
    "id": "4JMQPtXDHZES",
    "outputId": "492b2ec9-bbd5-4e50-d9c1-da93c04e0b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu y ban đầu  0\n",
      "Dữ liệu y sau one-hot encoding  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6500 samples, validate on 6500 samples\n",
      "Epoch 1/10\n",
      "6500/6500 [==============================] - 18s 3ms/step - loss: 0.7127 - acc: 0.7963 - val_loss: 0.1029 - val_acc: 0.9866\n",
      "Epoch 2/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0693 - acc: 0.9897 - val_loss: 0.0466 - val_acc: 0.9932\n",
      "Epoch 3/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0354 - acc: 0.9946 - val_loss: 0.0292 - val_acc: 0.9960\n",
      "Epoch 4/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0229 - acc: 0.9969 - val_loss: 0.0158 - val_acc: 0.9978\n",
      "Epoch 5/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0156 - acc: 0.9978 - val_loss: 0.0152 - val_acc: 0.9978\n",
      "Epoch 6/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0119 - acc: 0.9978 - val_loss: 0.0080 - val_acc: 0.9991\n",
      "Epoch 7/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0077 - acc: 0.9992 - val_loss: 0.0059 - val_acc: 0.9995\n",
      "Epoch 8/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0058 - acc: 0.9994 - val_loss: 0.0047 - val_acc: 0.9997\n",
      "Epoch 9/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0037 - val_acc: 0.9997\n",
      "Epoch 10/10\n",
      "6500/6500 [==============================] - 17s 3ms/step - loss: 0.0038 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "[0.0030515492329230677, 0.9996923076923077]\n",
      "Giá trị dự đoán:  0\n",
      "Saved model to drive\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "\n",
    "homePath = 'drive/My Drive/Colab Notebooks/data/'\n",
    "IMG_SIZE = 28\n",
    "NUMBER_CLASS = 10\n",
    "chars = [chr(i) for i in range(48,57)]\n",
    "NUM_TRAIN = 6500\n",
    "NUM_VAL = 7300\n",
    "# ham xu li du lieu\n",
    "def preprocessdata():\n",
    "    data=[]\n",
    "    label=[]\n",
    "    for i,char in enumerate(chars):\n",
    "        imgPath = homePath + char + '/'\n",
    "        imgFiles = os.listdir(imgPath)\n",
    "        for image in imgFiles:\n",
    "            img = cv2.imread(imgPath+ image,0)\n",
    "            data.append(img)\n",
    "            label.append(i)\n",
    "    l = len(label)\n",
    "    shutfle = list(range(l))\n",
    "    random.shuffle(shutfle)\n",
    "    train_data = np.array(data)\n",
    "    train_label = np.array(label)\n",
    "    train_data = train_data[shutfle]\n",
    "    train_label = train_label[shutfle]\n",
    "    return data,label\n",
    "\n",
    "data,label = preprocessdata()\n",
    "\n",
    "train_x = data[:NUM_TRAIN]\n",
    "train_y = label[:NUM_TRAIN]\n",
    "\n",
    "valid_x = data[NUM_TRAIN:NUM_VAL]\n",
    "valid_y = label[NUM_TRAIN:NUM_VAL]\n",
    "\n",
    "test_x = data[NUM_VAL:]\n",
    "test_y = data[NUM_VAL:]\n",
    "\n",
    "train_x = np.reshape(train_x,(-1,28,28,1))\n",
    "train_Y = np_utils.to_categorical(train_y, 10)\n",
    "valid_x = np.reshape(train_x,(-1,28,28,1))\n",
    "valid_Y = np_utils.to_categorical(train_y, 10)\n",
    "test_x = np.reshape(train_x,(-1,28,28,1))\n",
    "test_Y = np_utils.to_categorical(train_y, 10)\n",
    "\n",
    "print('Dữ liệu y ban đầu ',train_y[0])\n",
    "print('Dữ liệu y sau one-hot encoding ',train_Y[0])\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "H = model.fit(train_x, train_Y, validation_data=(valid_x, valid_Y),\n",
    "                 batch_size=32, epochs=10, verbose=1)\n",
    "score = model.evaluate(test_x, test_Y, verbose=0)\n",
    "print(score)\n",
    "plt.imshow(test_x[0].reshape(28,28), cmap='gray')\n",
    "y_predict = model.predict(test_x[0].reshape(1,28,28,1))\n",
    "print('Giá trị dự đoán: ', np.argmax(y_predict))\n",
    "model.save_weights(\"drive/My Drive/Colab Notebooks/model.h5\")\n",
    "print(\"Saved model to drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "XS9gV18B3eFg",
    "outputId": "f63ff2f0-264e-4b58-b55b-cd375d7927f6"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7b9c3e2c853d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/admin/Downloads/Project II/data/test/test_digits.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mim_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mim_blur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_gray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mthre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptiveThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_blur\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxValue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madaptiveMethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADAPTIVE_THRESH_GAUSSIAN_C\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthresholdType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY_INV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblockSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\color.cpp:11147: error: (-215) scn == 3 || scn == 4 in function cv::cvtColor\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "model.load_weights(\"C:/Users/admin/Downloads/Project II/model.h5\")\n",
    "\n",
    "image = cv2.imread(\"C:/Users/admin/Downloads/Project II/data/test/test_digits.jpg\")\n",
    "im_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "im_blur = cv2.GaussianBlur(im_gray,(5,5),0)\n",
    "thre = cv2.adaptiveThreshold(im_blur,maxValue=255,adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,thresholdType=cv2.THRESH_BINARY_INV,blockSize=29,C=9)\n",
    "_,contours,hierachy = cv2.findContours(thre,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "\n",
    "for i in contours:\n",
    "    results= [chr(char) for char in range(48, 57)]\n",
    "    minsize = 20\n",
    "    (x, y, w, h) = cv2.boundingRect(i)\n",
    "    if w > minsize and h > minsize:\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        roi = thre[y:y + h, x:x + w]\n",
    "        roi = np.pad(roi, (20, 20), 'constant', constant_values=(0, 0))\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = cv2.dilate(roi, (3, 3))\n",
    "        test_x = np.array([roi,])\n",
    "        number = model.predict(test_x.reshape(1,28,28,1))\n",
    "        numbers = np.argmax(number,axis=-1)\n",
    "        res = results[int(numbers)]\n",
    "        cv2.putText(image, str(res), (x, y),cv2.FONT_HERSHEY_DUPLEX, 3, (255, 255, 0), 3)\n",
    "cv2.namedWindow('im', cv2.WINDOW_NORMAL)\n",
    "cv2.imwrite('C:/Users/admin/Downloads/Project II/data/result.jpg', image)\n",
    "cv2.imshow('im', image)\n",
    "cv2.waitKey(20000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
